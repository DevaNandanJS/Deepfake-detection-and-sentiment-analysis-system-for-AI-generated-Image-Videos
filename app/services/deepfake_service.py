from transformers import AutoImageProcessor, AutoModelForImageClassification
from PIL import Image, UnidentifiedImageError
import torch
import cv2
import os

class DeepfakeDetector:
    """
    A service to detect whether an image or video frame is real or a deepfake using a
    pre-trained Hugging Face model. This implementation matches the official usage
    example for the model to ensure accuracy.
    """
    def __init__(self):
        """
        Initializes the DeepfakeDetector by loading the model and its processor
        from Hugging Face.
        """
        self.model_name = "prithivMLmods/Deep-Fake-Detector-v2-Model"
        try:
            self.processor = AutoImageProcessor.from_pretrained(self.model_name)
            self.model = AutoModelForImageClassification.from_pretrained(self.model_name)
        except Exception as e:
            print(f"Error loading model: {e}")
            raise

    async def detect(self, file_path: str) -> dict | None:
        """
        Asynchronously analyzes an image or video from a given file path to determine
        if it is a deepfake.

        Args:
            file_path: The path to the file to be analyzed.

        Returns:
            A dictionary with the 'label' ('REAL' or 'FAKE') and a 'score',
            or None if the analysis fails.
        """
        image = None
        try:
            image = Image.open(file_path).convert("RGB")
        except (FileNotFoundError, UnidentifiedImageError):
            try:
                cap = cv2.VideoCapture(file_path)
                ret, frame = cap.read()
                if ret:
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    image = Image.fromarray(frame_rgb)
                cap.release()
            except Exception as e:
                print(f"Error opening or processing file (image/video): {e}")
                return None

        if image is None:
            print(f"Could not extract any image from file: {file_path}")
            return None

        try:
            # Process the image and get tensors
            inputs = self.processor(images=image, return_tensors="pt")
            
            # Perform inference
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits

            # The model has two outputs: 'Deepfake' and 'Realism'.
            # Logits are raw scores. We apply softmax to get probabilities.
            # A higher score for 'Deepfake' means it's likely fake.
            # A higher score for 'Realism' means it's likely real.
            
            # Find the index of the 'FAKE'/'Deepfake' class
            fake_index = 0
            real_index = 1
            if self.model.config.id2label[0] == 'Realism':
                real_index = 0
                fake_index = 1
                
            # Get the probability of the image being FAKE
            # We are interested in the 'Deepfake' score
            probability = torch.nn.functional.softmax(logits, dim=1)[0][fake_index].item()
            
            # Determine label based on which logit is larger
            predicted_class_id = logits.argmax(-1).item()
            raw_label = self.model.config.id2label[predicted_class_id]
            
            if raw_label == 'Deepfake':
                label = 'FAKE'
                score = probability
            elif raw_label == 'Realism':
                label = 'REAL'
                score = 1 - probability # Score for 'REAL' is 1 - P(FAKE)
            else:
                label = raw_label # Fallback
                score = probability

            return {
                "label": label,
                "score": round(score, 4)
            }
        except Exception as e:
            print(f"Error during model inference: {e}")
            return None
